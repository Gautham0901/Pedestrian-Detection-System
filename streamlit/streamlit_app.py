import sys
from pathlib import Path

# Add the project root directory to Python path
project_root = Path(__file__).parent.parent
if str(project_root) not in sys.path:
    sys.path.append(str(project_root))

import streamlit as st
import cv2
import numpy as np
import torch
from modules.detector import ObjectDetector
from modules.xai import XAIVisualizer
from modules.integrated_detector import IntegratedDetectorTracker
import tempfile
import os
from datetime import datetime
import plotly.express as px
import pandas as pd

# Page config
st.set_page_config(
    page_title="Pedestrian Detection System",
    page_icon="üö∂",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Initialize detector
def initialize_detector():
    try:
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        st.sidebar.info(f"Using device: {device}")
        
        # Initialize detector
        detector = IntegratedDetectorTracker(
            model_path=str(project_root / "models" / "yolov10x.pt"),
            conf_thresh=0.3
        )
        
        # Move detector's model to device
        detector.detector.model = detector.detector.model.to(device)
        
        # Initialize XAI visualizer with the correct model reference
        xai_visualizer = XAIVisualizer(detector.detector.model)
        
        st.session_state['detector'] = detector
        st.session_state['xai_visualizer'] = xai_visualizer
        return detector, xai_visualizer
    except Exception as e:
        st.error(f"Error initializing detector: {str(e)}")
        return None, None

def process_frame(frame, detector, xai_visualizer, settings, metrics):
    try:
        processed_frame = frame.copy()
        results = detector.detect_and_track(frame)
        
        # Update metrics
        metrics.update(results)
        
        # Process each detection
        for det in results:
            bbox = det['bbox']
            x1, y1, w, h = map(int, bbox)
            x2, y2 = x1 + w, y1 + h
            
            # Draw bounding box if enabled
            if settings.get('show_boxes', True):
                cv2.rectangle(processed_frame, (x1, y1), (x2, y2), det['color'], 2)
            
            # Draw label if enabled
            if settings.get('show_labels', True):
                track_id = det.get('track_id', None)
                label = f"{det['class_name']}: {det['confidence']:.2f}"
                if track_id is not None:
                    label += f" ID: {track_id}"
                cv2.putText(processed_frame, label, (x1, y1-10),
                          cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)
            
            # Generate and overlay XAI visualization
            processed_frame = xai_visualizer.generate_saliency_map(processed_frame.copy(), det)
        
        return processed_frame, results
    except Exception as e:
        st.error(f"Error processing frame: {e}")
        return frame, []

# Add custom CSS
def load_css():
    st.markdown("""
        <style>
        /* Dashboard theme */
        .stApp {
            background-color: #0E1117;
        }
        .dashboard-header {
            background: linear-gradient(90deg, #1E1E1E 0%, #2C3E50 100%);
            padding: 2rem;
            border-radius: 15px;
            margin-bottom: 2rem;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
        }
        .dashboard-section {
            background: rgba(45, 45, 45, 0.7);
            padding: 1.5rem;
            border-radius: 15px;
            border: 1px solid #3E3E3E;
            margin: 1rem 0;
        }
        .video-player {
            background: #1E1E1E;
            padding: 1rem;
            border-radius: 12px;
            margin: 1rem 0;
        }
        .download-button {
            background: #00FF88;
            color: #1E1E1E;
            padding: 0.8rem 1.5rem;
            border-radius: 8px;
            text-align: center;
            font-weight: bold;
            cursor: pointer;
            transition: all 0.3s ease;
        }
        .download-button:hover {
            background: #00CC6A;
            transform: translateY(-2px);
        }
        .main-header {
            background: linear-gradient(90deg, #1E1E1E 0%, #2C3E50 100%);
            padding: 2rem;
            border-radius: 15px;
            margin-bottom: 2rem;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
        }
        .metric-card {
            background: linear-gradient(145deg, #2E2E2E, #1E1E1E);
            padding: 1.5rem;
            border-radius: 12px;
            margin: 1rem 0;
            box-shadow: 0 4px 15px rgba(0, 0, 0, 0.2);
            transition: transform 0.3s ease;
        }
        .metric-card:hover {
            transform: translateY(-5px);
        }
        .metric-value {
            font-size: 2rem;
            font-weight: bold;
            color: #00FF88;
        }
        .metric-label {
            color: #AAA;
            font-size: 1rem;
        }
        .upload-section {
            background: rgba(45, 45, 45, 0.7);
            padding: 2rem;
            border-radius: 15px;
            border: 1px solid #3E3E3E;
            margin: 2rem 0;
        }
        .status-box {
            background: rgba(30, 30, 30, 0.8);
            padding: 1rem;
            border-radius: 8px;
            margin: 1rem 0;
        }
        /* Custom progress bar */
        .stProgress > div > div {
            background-color: #00FF88;
        }
        </style>
    """, unsafe_allow_html=True)

# At the top of the file, after project_root definition
# Create necessary directories
reports_dir = project_root / "reports"
reports_dir.mkdir(exist_ok=True)

def save_processed_video(frames, fps, path):
    # Create reports directory if it doesn't exist
    output_dir = reports_dir / "videos"
    output_dir.mkdir(exist_ok=True)
    
    height, width = frames[0].shape[:2]
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(str(path), fourcc, fps, (width, height))
    for frame in frames:
        out.write(frame)
    out.release()

def generate_report(metrics, duration, filename):
    # Handle empty metrics gracefully
    peak_count = max(metrics.detection_history) if metrics.detection_history else 0
    min_count = min(metrics.detection_history) if metrics.detection_history else 0
    avg_detections = (metrics.total_detections/metrics.frames_processed) if metrics.frames_processed > 0 else 0
    
    report = f"""
    # Pedestrian Detection Analysis Report
    
    ## Video Information
    - Filename: {filename}
    - Duration: {duration:.2f} seconds
    - Total Frames: {metrics.frames_processed}
    
    ## Detection Statistics
    - Total Detections: {metrics.total_detections}
    - Average Detections per Frame: {avg_detections:.2f}
    - Average Confidence Score: {metrics.avg_confidence:.2f}%
    
    ## Analysis Summary
    - Peak Detection Count: {peak_count}
    - Minimum Detection Count: {min_count}
    
    ## Processing Information
    - Processing Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
    - Model: YOLOv10x
    """
    return report

# Add to imports
from PIL import Image
import io
import base64

class DetectionMetrics:
    def __init__(self):
        self.total_detections = 0
        self.frames_processed = 0
        self.avg_confidence = 0
        self.detection_history = []
        self.processed_frames = []

    def update(self, detections):
        self.frames_processed += 1
        self.total_detections += len(detections)
        if detections:
            confidences = [det['confidence'] for det in detections]
            self.avg_confidence = sum(confidences) / len(confidences)
            self.detection_history.append(len(detections))

@st.cache_data
def process_video_chunk(frames, detector, settings):
    results = []
    for frame in frames:
        result = detector.detect_and_track(frame)
        results.append(result)
    return results

# Add this function before main()
def display_results(metrics, processed_frames, output_path, filename, fps):
    # Display metrics dashboard
    st.markdown("## üìä Analysis Dashboard")
    
    # Metrics cards in grid layout
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown(f"""
            <div class="metric-card">
                <div class="metric-value">{metrics.total_detections}</div>
                <div class="metric-label">Total Detections</div>
            </div>
        """, unsafe_allow_html=True)
    
    with col2:
        st.markdown(f"""
            <div class="metric-card">
                <div class="metric-value">{metrics.frames_processed}</div>
                <div class="metric-label">Frames Analyzed</div>
            </div>
        """, unsafe_allow_html=True)
    
    with col3:
        st.markdown(f"""
            <div class="metric-card">
                <div class="metric-value">{metrics.avg_confidence:.1f}%</div>
                <div class="metric-label">Average Confidence</div>
            </div>
        """, unsafe_allow_html=True)

    # Detection trend visualization
    st.markdown("### üìà Detection Trends")
    if metrics.detection_history:
        df = pd.DataFrame({
            'Frame': range(len(metrics.detection_history)),
            'Detections': metrics.detection_history
        })
        fig = px.line(df, x='Frame', y='Detections', 
                     title='Pedestrian Detections Over Time')
        fig.update_layout(
            plot_bgcolor='rgba(0,0,0,0)',
            paper_bgcolor='rgba(0,0,0,0)',
            font_color='#CCCCCC'
        )
        st.plotly_chart(fig, use_container_width=True)

    # Video playback and download section
    # st.markdown("### üé• Processed Video")
    # st.video(str(output_path))
    
    # Download buttons
    col1, col2 = st.columns(2)
    with col1:
        with open(output_path, 'rb') as f:
            st.download_button(
                "üì• Download Processed Video",
                f.read(),
                file_name=f"processed_{filename}",
                mime="video/mp4"
            )
    
    with col2:
        report = generate_report(metrics, len(processed_frames)/fps, filename)
        st.download_button(
            "üìÑ Download Analysis Report",
            report,
            file_name="detection_report.txt",
            mime="text/markdown"
        )

def main():
    load_css()
    
    # Initialize metrics and detector
    if 'metrics' not in st.session_state:
        st.session_state.metrics = DetectionMetrics()
    
    if 'detector' not in st.session_state or 'xai_visualizer' not in st.session_state:
        detector, xai_visualizer = initialize_detector()
        if detector is None or xai_visualizer is None:
            st.error("Failed to initialize detector")
            return
    else:
        detector = st.session_state['detector']
        xai_visualizer = st.session_state['xai_visualizer']

    # Enhanced header with animation
    st.markdown("""
        <div class="main-header">
            <h1 style='color: white; font-size: 2.5rem; margin-bottom: 0.5rem;'>
                üö∂ Pedestrian Detection System
            </h1>
            <p style='color: #AAA; font-size: 1.2rem;'>
                Advanced real-time detection with explainable AI visualization
            </p>
        </div>
    """, unsafe_allow_html=True)

    # Sidebar enhancement
    with st.sidebar:
        st.markdown("## üéÆ Control Panel")
        st.markdown("---")
        settings = {
            'show_boxes': st.checkbox("üì¶ Bounding Boxes", value=True, help="Show detection boxes around pedestrians"),
            'show_labels': st.checkbox("üè∑Ô∏è Labels & Confidence", value=True, help="Display detection labels and confidence scores"),
            'show_xai': st.checkbox("üîç XAI Visualization", value=True, help="Show model's attention areas")
        }
        
        st.markdown("---")
        st.markdown("### üõ†Ô∏è Model Settings")
        confidence_threshold = st.slider("Confidence Threshold", 0.0, 1.0, 0.3, 0.05)

    # Main content area
    st.markdown("""
        <div class="upload-section">
            <h3 style='color: white;'>üì§ Upload Video for Analysis</h3>
            <p style='color: #AAA;'>Support formats: MP4, AVI, MOV</p>
        </div>
    """, unsafe_allow_html=True)
    
    video_file = st.file_uploader("", type=['mp4', 'avi', 'mov'])

    if video_file is not None:
        # Processing status
        status_container = st.container()
        with status_container:
            st.markdown('<div class="status-box">', unsafe_allow_html=True)
            progress_bar = st.progress(0)
            status_text = st.empty()
            st.markdown('</div>', unsafe_allow_html=True)

        try:
            # Reset metrics and initialize processing
            st.session_state.metrics = DetectionMetrics()
            processed_frames = []
            
            # Create output path for processed video
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_path = reports_dir / "videos" / f"processed_{timestamp}_{video_file.name}"
            output_path.parent.mkdir(exist_ok=True)

            # Process video in chunks
            with tempfile.NamedTemporaryFile(delete=False, suffix='.mp4') as tfile:
                tfile.write(video_file.read())
                video_path = tfile.name

                cap = cv2.VideoCapture(video_path)
                total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
                fps = int(cap.get(cv2.CAP_PROP_FPS))

                if not cap.isOpened():
                    st.error("Error opening video file")
                    return

                # Process frames
                frame_count = 0
                while cap.isOpened():
                    ret, frame = cap.read()
                    if not ret:
                        break

                    frame_count += 1
                    progress_bar.progress(frame_count / total_frames)
                    status_text.text(f"Processing frame {frame_count}/{total_frames}")

                    processed_frame, detections = process_frame(
                        frame, detector, xai_visualizer, settings, st.session_state.metrics
                    )
                    processed_frames.append(processed_frame)

                # Save and display results
                save_processed_video(processed_frames, fps, output_path)
                
                # Display dashboard and metrics
                display_results(
                    st.session_state.metrics,
                    processed_frames,
                    output_path,
                    video_file.name,
                    fps
                )

        finally:
            if 'cap' in locals():
                cap.release()
            if 'video_path' in locals():
                try:
                    os.unlink(video_path)
                except Exception:
                    pass

def display_metrics_dashboard():
    st.markdown("## üìä Performance Analysis")
    col1, col2, col3, col4 = st.columns(4)

    with col1:
        st.markdown("""
            <div class="metric-card">
                <div class="metric-value">85%</div>
                <div class="metric-label">System's Precision</div>
            </div>
        """, unsafe_allow_html=True)

    with col2:
        st.markdown("""
            <div class="metric-card">
                <div class="metric-value">89%</div>
                <div class="metric-label">System's Recall</div>
            </div>
        """, unsafe_allow_html=True)

    with col3:
        st.markdown("""
            <div class="metric-card">
                <div class="metric-value">30</div>
                <div class="metric-label">FPS</div>
            </div>
        """, unsafe_allow_html=True)

    with col4:
        st.markdown("""
            <div class="metric-card">
                <div class="metric-value">Active</div>
                <div class="metric-label">Status</div>
            </div>
        """, unsafe_allow_html=True)



def main():
    load_css()
    
    # Initialize metrics and detector
    if 'metrics' not in st.session_state:
        st.session_state.metrics = DetectionMetrics()
    
    if 'detector' not in st.session_state or 'xai_visualizer' not in st.session_state:
        detector, xai_visualizer = initialize_detector()
        if detector is None or xai_visualizer is None:
            st.error("Failed to initialize detector")
            return
    else:
        detector = st.session_state['detector']
        xai_visualizer = st.session_state['xai_visualizer']

    # Enhanced header with animation
    st.markdown("""
        <div class="main-header">
            <h1 style='color: white; font-size: 2.5rem; margin-bottom: 0.5rem;'>
                üö∂ Pedestrian Detection System
            </h1>
            <p style='color: #AAA; font-size: 1.2rem;'>
                Advanced real-time detection with explainable AI visualization
            </p>
        </div>
    """, unsafe_allow_html=True)

    # Sidebar enhancement
    with st.sidebar:
        st.markdown("## üéÆ Control Panel")
        st.markdown("---")
        settings = {
            'show_boxes': st.checkbox("üì¶ Bounding Boxes", value=True, help="Show detection boxes around pedestrians"),
            'show_labels': st.checkbox("üè∑Ô∏è Labels & Confidence", value=True, help="Display detection labels and confidence scores"),
            'show_xai': st.checkbox("üîç XAI Visualization", value=True, help="Show model's attention areas")
        }
        
        st.markdown("---")
        st.markdown("### üõ†Ô∏è Model Settings")
        confidence_threshold = st.slider("Confidence Threshold", 0.0, 1.0, 0.3, 0.05)

    # Display metrics dashboard
    display_metrics_dashboard()

    # Main content area
    st.markdown("""
        <div class="upload-section">
            <h3 style='color: white;'>üì§ Upload Video for Analysis</h3>
            <p style='color: #AAA;'>Support formats: MP4, AVI, MOV</p>
        </div>
    """, unsafe_allow_html=True)
    
    video_file = st.file_uploader("", type=['mp4', 'avi', 'mov'])

    if video_file is not None:
        # Processing status
        status_container = st.container()
        with status_container:
            st.markdown('<div class="status-box">', unsafe_allow_html=True)
            progress_bar = st.progress(0)
            status_text = st.empty()
            st.markdown('</div>', unsafe_allow_html=True)

        try:
            # Reset metrics and initialize processing
            st.session_state.metrics = DetectionMetrics()
            processed_frames = []
            
            # Create output path for processed video
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_path = reports_dir / "videos" / f"processed_{timestamp}_{video_file.name}"
            output_path.parent.mkdir(exist_ok=True)

            # Process video in chunks
            with tempfile.NamedTemporaryFile(delete=False, suffix='.mp4') as tfile:
                tfile.write(video_file.read())
                video_path = tfile.name

                cap = cv2.VideoCapture(video_path)
                total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
                fps = int(cap.get(cv2.CAP_PROP_FPS))

                if not cap.isOpened():
                    st.error("Error opening video file")
                    return

                # Process frames
                frame_count = 0
                while cap.isOpened():
                    ret, frame = cap.read()
                    if not ret:
                        break

                    frame_count += 1
                    progress_bar.progress(frame_count / total_frames)
                    status_text.text(f"Processing frame {frame_count}/{total_frames}")

                    processed_frame, detections = process_frame(
                        frame, detector, xai_visualizer, settings, st.session_state.metrics
                    )
                    processed_frames.append(processed_frame)

                # Save and display results
                save_processed_video(processed_frames, fps, output_path)
                
                # Display dashboard and metrics
                display_results(
                    st.session_state.metrics,
                    processed_frames,
                    output_path,
                    video_file.name,
                    fps
                )

        finally:
            if 'cap' in locals():
                cap.release()
            if 'video_path' in locals():
                try:
                    os.unlink(video_path)
                except Exception:
                    pass

    # Display footer

if __name__ == "__main__":
    main()